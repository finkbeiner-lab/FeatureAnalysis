---
title: "MultiTimepoint_RMedPower_final"
output: html_document
date: "2024-03-07"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)

library(lmerTest)
require(ggplot2)
library(plyr)
library(EnvStats)
library(gridExtra)
library(readxl)
library(writexl)
library(openxlsx)
library(tidyr)
library(magrittr)
library(xtable)
library(dplyr)
library(reshape2)
library(devtools)
library(RMeDPower)
library(RColorBrewer)

source("~/Dropbox (Gladstone)/calcPower f1000_manuscript/scripts/beta_test/transform_data.R")
source("~/Dropbox (Gladstone)/calcPower f1000_manuscript/scripts/visualize_two_variable_associations.R")

```

## R Markdown

This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see <http://rmarkdown.rstudio.com>.

When you click the **Knit** button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this:

```{r cars}
data_path <- "~/Dropbox (Gladstone)/calcPower f1000_manuscript/Cortical RMedPower Data/Data/"
output_path <- "~/Dropbox (Gladstone)/Stephanie/NucleiML_HDCortical/CorticalMorphology/2024/RUES2/Multi Timepoint/Mar2024/20CAG72CAG"
setwd(output_path)

experiments <- c("COR16","COR21SYNEGFP", "COR24PLATE2","COR25PLATE2",
                 "COR27","COR29-plate1-20201207",
                 "COR45-plate2","COR46-p1-SYNeGFP","COR48-p1-SYNeGFP","COR50-p1-SYNeGFP")

#dropping some features for now
drop_features <- c("brightness","bright.pixel","brightnessK","brightnessI", "skel_length", "skel_branches","corners","scharr","fft.power", "noise","sholl_total")
order <- c("20CAG30","20CAG65","72CAG2","72CAG9","72CAG12","KO8A")

categorical_fetaures <- c("edge", "sholl_med","sholl_total")

```

```{r read data, echo=FALSE}
csvs = list.files(data_path, pattern="*.csv", recursive = TRUE, full.names = TRUE)

#remove any platelayout csv from list
csvs = csvs[! grepl("platelayout.csv", csvs) ]
csvs = csvs[! grepl("ignore", csvs) ]

#keep only wanted experiments
csvs = csvs[ grepl(paste(experiments, collapse = "|"), csvs) ]

#combine experiments csv
myfiles = lapply(csvs, read.csv)
input_data = do.call(bind_rows, myfiles)

#drop feature/cell lines
input_data <- input_data[ , !(names(input_data) %in% drop_features)]

input_data$classif[grepl("KO", input_data$cellline, ignore.case=FALSE)] <- "2"
input_data$classif[grepl("72CAG", input_data$cellline, ignore.case=FALSE)] <- "1"
input_data$classif[grepl("20CAG", input_data$cellline, ignore.case=FALSE)] <- "0"

#Remove KO class
input_data <- input_data[input_data$classif != "2",]
input_data$classif<- as.factor(input_data$classif)

names(input_data)[names(input_data) == 'exp'] <- 'experiment'

#take care of cell lines
input_data$experiment = as.factor(input_data$experiment)
names(input_data)[names(input_data) == 'cellline'] <- 'line'
input_data$line=as.factor(input_data$line)
input_data$line = gsub("Untreated-|Untreated_","",input_data$line)
input_data$line = gsub("COD9-","",input_data$line)
input_data$line = as.factor(input_data$line)

#take care of timepoints, extract timepoint string from ident
input_data$timepoint <- unlist(lapply(1:length(input_data$ident),
                                      function(x) strsplit(as.character(input_data$ident[x]),"_")[[1]][3]))
input_data$timepoint  = as.factor(input_data$timepoint)
input_data$timepoint  = gsub('[Tt]','',input_data$timepoint)
input_data$timepoint = as.factor(as.numeric(as.character(input_data$timepoint)))

#replace timepoint values......
input_data$new_timepoint = input_data$timepoint
input_data$new_timepoint[input_data$new_timepoint == 0] <- 1
input_data$new_timepoint[input_data$new_timepoint == 2] <- 1
input_data$new_timepoint[input_data$new_timepoint != 1] <- 8

input_data <- subset(input_data, select = -c(timepoint))
names(input_data)[names(input_data) == "new_timepoint"] <- "timepoint"
input_data$timepoint  = factor(input_data$timepoint)

Data <- input_data
Data <- Data %>% dplyr::select(c("ident", "classif", "line", "experiment","timepoint"), everything())
Data$line <- factor(Data$line, levels = order)

##CHECK ACCORDING TO THE DATA: Column indices in the Data data.frame with information regarding experiment, condition
VariablesOfInterestIndices <- 1:which(colnames(Data)=="timepoint")
cat("VariablesOfInterestIndices \n")
print(names(Data)[1:which(colnames(Data)=="timepoint")])
cat("\n")

####CHECK ACCORDING TO THE DATA: Column indices in the Data data.frame with information regarding responses of interest
cat("ResponsesOfInterestIndices \n")
ResponsesOfInterestIndices <- (which(colnames(Data)=="timepoint")+1):ncol(Data)
print(names(Data)[(which(colnames(Data)=="timepoint")+1):ncol(Data)])
cat("\n")

sum_original = Data %>% group_by(experiment, timepoint) %>% dplyr::summarise(n=n())
sum_original_line = Data %>% group_by(experiment, timepoint, line) %>% dplyr::summarise(n=n())
write.csv(Data, file.path(output_path,"original_data.csv"))
write.csv(sum_original,  file.path(output_path,"original_data_points.csv"))
write.csv(sum_original_line,  file.path(output_path,"original_data_points_line.csv"))
```

```{r transform_data}

#remove outliers + transform data
#create transformed_df with variables of interest.
transformed_col <- NULL
transformed_df <- Data[c(1:which(colnames(Data)=="timepoint"))]


#add features after transformation (with outliers/logTransformed, removed outliers/noOutliers, or no transformatio)

for(i in ResponsesOfInterestIndices){
  feature = names(Data)[i]
  cat(paste0("transformaing data for feature: ",feature," \n"))
  
  transformed_col=transform_data(data=Data, condition_column="classif",
                                 experimental_columns=c("experiment","line"), response_column=feature,
                                 condition_is_categorical=TRUE,
                                 repeatable_columns = "line",
                                 response_is_categorical=FALSE, alpha=0.05)
  
  if(feature %in% categorical_fetaures){
    if (any(grepl(paste0(feature,"_noOutlier"),colnames(transformed_col)))){
      col_index = which(grepl(paste0(feature,"_noOutlier"),colnames(transformed_col)))
    }
  }else{
    if (any(grepl("_logTransformed_noOutlier",colnames(transformed_col)))){
      col_index = which(grepl("_logTransformed_noOutlier",colnames(transformed_col)))
    }else if (any(grepl("_logTransformed$",colnames(transformed_col)))){
      col_index = which(grepl("_logTransformed$",colnames(transformed_col)))
    }else{
      cat("No transformation done")
      col_index = which(grepl(feature,colnames(transformed_col)))
    }
    
  }
  
  #rename feature and store in new transformed dataframe
  transformed_merge = data.frame("ident" = transformed_col[,c("ident")],
                                 transformed_col[,col_index])
  transformed_df <- merge(transformed_df, transformed_merge)
  #transformed_df<- cbind(transformed_df, transformed_col[,col_index])
  colnames(transformed_df)[ncol(transformed_df)] <- feature
}

output_path_string <- basename(output_path)
write.csv(transformed_df,file.path(output_path,paste0(output_path_string,"_transformed_df.csv")))
sum_transformed = transformed_df %>% group_by(experiment, timepoint) %>% dplyr::summarise(n=n())
sum_transformed_line = transformed_df %>% group_by(experiment, timepoint, line) %>% dplyr::summarise(n=n())
write.csv(sum_transformed,  file.path(output_path,"transformed_data_points.csv"))
write.csv(sum_transformed_line,  file.path(output_path,"transformed_data_points_line.csv"))

```

```{r model}

##Fit the model

#adjusted for multi timepoints
calculate_lmer_estimates <- function(data, condition_column, experimental_columns, response_column, condition_is_categorical,
                                     repeatable_columns=NA, response_is_categorical=FALSE, family=NULL, na.action="complete"){
  
  
  
  ######input error handler
  if(!condition_column%in%colnames(data)){ print("condition_column should be one of the column names");return(NULL) }
  if(sum(experimental_columns%in%colnames(data))!=length(experimental_columns) ){ print("experimental_columns must match column names");return(NULL) }
  if(!response_column%in%colnames(data)){  print("response_column should be one of the column names");return(NULL) }
  if(is.null(condition_is_categorical) | !condition_is_categorical%in%c(TRUE,FALSE)){ print("condition_is_categorical must be TRUE or FALSE");return(NULL) }
  if(!is.na(repeatable_columns)){if(sum(repeatable_columns%in%colnames(data))!=length(repeatable_columns) ){ print("repeatable_columns must match column names");return(NULL) }}
  
  if(response_is_categorical==TRUE){
    family=switch(family, "poisson" = poisson(link="log"), "binomial" = binomial(link="logit"), "bionomial_log" = binomial(link="log") )
  }
  
  
  if(na.action=="complete"){
    
    notNAindex=which( rowSums(is.na(data)) == 0 )
    
  }else if(na.action=="unique"){
    
    notNAindex=which( rowSums(is.na(data[,c(condition_column, experimental_columns, response_column)])) == 0 )
    
  }
  
  Data=data[notNAindex,]
  
  
  cat("\n")
  print("__________________________________________________________________Summary of data:")
  print(summary(Data))
  cat("\n")
  
  colnames_original=colnames(Data)
  experimental_columns_index=NULL
  ####### assign categorical variables
  if(condition_is_categorical==TRUE) Data[,condition_column]=as.factor(Data[,condition_column])
  
  cat("\n")
  
  
  
  nonrepeatable_columns=NULL
  
  for(i in 1:length(experimental_columns)){
    Data[,experimental_columns[i]]=as.factor(Data[,experimental_columns[i]])
    experimental_columns_index=c(experimental_columns_index,which(colnames(Data)==experimental_columns[i]))
    colnames(Data)[experimental_columns_index[i]]=paste("experimental_column",i,sep="")
    
    if(i!=1&&!experimental_columns[i]%in%repeatable_columns){
      nonrepeatable_columns=c(nonrepeatable_columns, paste("experimental_column",i,sep=""))
    }
    
    
    cat("\n")
    print(paste("_________________________________",experimental_columns[i]," is assigned to experimental_column",i,sep=""))
    cat("\n")
  }
  
  
  
  if(length(experimental_columns)>=2){
    for(r in 2:length(experimental_columns)){
      if(colnames(Data)[experimental_columns_index[r]]%in%nonrepeatable_columns){
        Data[,experimental_columns_index[r]]=paste(Data[,experimental_columns_index[r-1]], Data[,experimental_columns_index[r]],sep="_")
      }
    }
    
  }
  
  
  colnames(Data)[which(colnames(Data)==condition_column)]="condition_column"
  colnames(Data)[which(colnames(Data)==response_column)]="response_column"
  
  
  ####### run the formula
  
  if(response_is_categorical==FALSE){
    if(length(experimental_columns)==1){
      lmerFit <- lmerTest::lmer(response_column ~ condition_column + (1 | experimental_column1) + timepoint + condition_column:timepoint, data=Data)
    }else if(length(experimental_columns)==2){
      lmerFit <- lmerTest::lmer(response_column ~ condition_column + (1 | experimental_column1) + (1 | experimental_column2) + timepoint + condition_column:timepoint, data=Data)
    }else if(length(experimental_columns)==3){
      lmerFit <- lmerTest::lmer(response_column ~ condition_column + (1 | experimental_column1) + (1 | experimental_column2) + (1 | experimental_column3) + timepoint + condition_column:timepoint, data=Data)
    }else if(length(experimental_columns)==4){
      lmerFit <- lmerTest::lmer(response_column ~ condition_column + (1 | experimental_column1) + (1 | experimental_column2) + (1 | experimental_column3) + (1 | experimental_column4) + timepoint + condition_column:timepoint, data=Data)
    }else if(length(experimental_columns)==5){
      lmerFit <- lmerTest::lmer(response_column ~ condition_column + (1 | experimental_column1) + (1 | experimental_column2) + (1 | experimental_column3) + (1 | experimental_column4) + (1 | experimental_column5) + timepoint + condition_column:timepoint, data=Data)
      
    }
  }else{
    if(length(experimental_columns)==1){
      lmerFit <- lme4::glmer(response_column ~ condition_column + (1 | experimental_column1) + timepoint + condition_column:timepoint, data=Data, family=family)
    }else if(length(experimental_columns)==2){
      lmerFit <- lme4::glmer(response_column ~ condition_column + (1 | experimental_column1) + (1 | experimental_column2)+ timepoint + condition_column:timepoint, data=Data, family=family)
    }else if(length(experimental_columns)==3){
      lmerFit <- lme4::glmer(response_column ~ condition_column + (1 | experimental_column1) + (1 | experimental_column2) + (1 | experimental_column3) + timepoint + condition_column:timepoint, data=Data, family=family)
    }else if(length(experimental_columns)==4){
      lmerFit <- lme4::glmer(response_column ~ condition_column + (1 | experimental_column1) + (1 | experimental_column2) + (1 | experimental_column3) + (1 | experimental_column4)+ timepoint + condition_column:timepoint, data=Data, family=family)
    }else if(length(experimental_columns)==5){
      lmerFit <- lme4::glmer(response_column ~ condition_column + (1 | experimental_column1) + (1 | experimental_column2) + (1 | experimental_column3) + (1 | experimental_column4) + (1 | experimental_column5) + timepoint + condition_column:timepoint, data=Data, family=family)
    }
  }
  
  slmerFit <- summary(lmerFit)
  cat("\n")
  print("__________________________________________________________________Model statistics:")
  print(slmerFit)
  cat("\n")
  
  return(slmerFit)
}

# generate empty frames
results_transformed_estimate=NULL
results_transformed_stdE=NULL
results_transformed_df=NULL
results_transformed_raw_p=NULL
results_transformed_corrected_p=NULL

fixed_effects <- c("condition_column1", "timepoint8", "cndtn_cl1:8")


transformed_df_copy = transformed_df
notNAindex=which( rowSums(is.na(transformed_df)) == 0 )
NAindex=which( rowSums(is.na(transformed_df)) != 0 )
na_df = transformed_df[NAindex,]
dropped_df=transformed_df[notNAindex,]
final_resi_box=dropped_df[,1:which(colnames(Data)=="timepoint")]

dfcombine <- NULL


for(i in ResponsesOfInterestIndices){
  feature = names(transformed_df)[i]
  
  cat(paste0("Lmer estimate for feature: ",feature," \n"))
  if(feature %in% categorical_fetaures){
    lmer_summary = calculate_lmer_estimates(data=transformed_df, 
                                            condition_column="classif", 
                                            experimental_columns=c("experiment","line"),
                                            response_column=feature,
                                            condition_is_categorical=TRUE,
                                            repeatable_columns="line",
                                            response_is_categorical=TRUE,
                                            family="poisson")
    
    results_transformed_estimate=cbind(results_transformed_estimate,lmer_summary$coefficients[,1][2:4])
    results_transformed_stdE=cbind(results_transformed_stdE,lmer_summary$coefficients[,2][2:4])
    results_transformed_df=cbind(results_transformed_df,lmer_summary$coefficients[,3][2:4])
    results_transformed_raw_p=cbind(results_transformed_raw_p,lmer_summary$coefficients[,4][2:4])
    
    pdf(paste0(output_path, '/',feature, "_plots.pdf"))
    viz_results <- visualize_two_variable_association(data = transformed_df,
                                                      condition_column = "classif",
                                                      experimental_columns = c("experiment","line"),
                                                      response_column = feature,
                                                      condition_is_categorical = TRUE,
                                                      covariate="timepoint",
                                                      repeatable_columns="line",
                                                      response_is_categorical=TRUE,
                                                      family_p="poisson",
                                                      na.action="complete")
    dev.off()
    
    write.csv(viz_results$data.residuals, paste0(output_path,  '/',feature,"_data_residuals.csv"))
    write.csv(viz_results$data.summary, paste0(output_path,  '/',feature,"_data_summary.csv"))
    write.csv(viz_results$data.mean.se, paste0(output_path,  '/',feature,"_data_mean_se.csv"))
    
  }else{
    lmer_summary = calculate_lmer_estimates(data=transformed_df, 
                                            condition_column="classif", 
                                            experimental_columns=c("experiment", "line"),
                                            response_column=feature,
                                            condition_is_categorical=TRUE,
                                            repeatable_columns="line",
                                            response_is_categorical=FALSE,
                                            family=NULL)
    
    results_transformed_estimate=cbind(results_transformed_estimate,lmer_summary$coefficients[,1][2:4])
    results_transformed_stdE=cbind(results_transformed_stdE,lmer_summary$coefficients[,2][2:4])
    results_transformed_df=cbind(results_transformed_df,lmer_summary$coefficients[,3][2:4])
    results_transformed_raw_p=cbind(results_transformed_raw_p,lmer_summary$coefficients[,5][2:4])
    
    pdf(paste0(output_path, '/',feature, "_plots.pdf"))
    viz_results <- visualize_two_variable_association(data = transformed_df,
                                                      condition_column = "classif",
                                                      experimental_columns = c("experiment","line"),
                                                      response_column = feature,
                                                      condition_is_categorical = TRUE,
                                                      covariate="timepoint",
                                                      repeatable_columns="line",
                                                      response_is_categorical=FALSE,
                                                      family_p=NULL,
                                                      na.action="complete")
    dev.off()
    
    write.csv(viz_results$data.residuals, paste0(output_path,  '/',feature,"_data_residuals.csv"))
    write.csv(viz_results$data.summary, paste0(output_path,  '/',feature,"_data_summary.csv"))
    write.csv(viz_results$data.mean.se, paste0(output_path,  '/',feature,"_data_mean_se.csv"))
    
  }
  

  ##viz_results is made up of three data.frames; You can save these and plot in Prism
  #viz_results$data.residuals : residuals per observation
  #viz_results$data.summary : mean residuals per experimental_column1 (experiment)
  #viz_results$data.mean.se: mean and se of each feature value at combination of condition_column (classif) and covariate (timepoint)
  
  resi_box = NULL
  resi_box <- rbind(resi_box, viz_results$data.residuals)
  final_resi_box <- cbind(final_resi_box, resi_box$residual)
  colnames(final_resi_box)[which(names(final_resi_box) == "resi_box$residual")] <- feature
  
}

colnames(results_transformed_estimate)=colnames(transformed_df)[ResponsesOfInterestIndices]

colnames(results_transformed_stdE)=colnames(transformed_df)[ResponsesOfInterestIndices]
colnames(results_transformed_df)=colnames(transformed_df)[ResponsesOfInterestIndices]
colnames(results_transformed_raw_p)=colnames(transformed_df)[ResponsesOfInterestIndices]

results_transformed_corrected_p=results_transformed_raw_p
colnames(results_transformed_corrected_p)=colnames(transformed_df)[ResponsesOfInterestIndices]

results_transformed_corrected_p=matrix(p.adjust(results_transformed_raw_p,method="BH"),nrow=3,ncol=ncol(results_transformed_raw_p),)
colnames(results_transformed_corrected_p)=colnames(results_transformed_raw_p)
row.names(results_transformed_corrected_p) = fixed_effects


xlsx_name = file.path(output_path,paste0(output_path_string,"_Residuals.xlsx"))
write.xlsx(list("corrected_pvalue" = as.data.frame(results_transformed_corrected_p),
                "raw_pvalue" = as.data.frame(results_transformed_raw_p),
                "estimate" = as.data.frame(results_transformed_estimate),
                "std_error" = as.data.frame(results_transformed_stdE),
                "degree_of_freedom" = as.data.frame(results_transformed_df),
                "feature_residuals" = final_resi_box),
           xlsx_name, rowNames=TRUE)


```

```{r heatmaps}
interaction_estimates <- results_transformed_estimate[-(1:2),]
estimate_heatmap <- as.data.frame(interaction_estimates)
estimate_heatmap['row'] <- rownames(estimate_heatmap)
df.molten_est <- melt(estimate_heatmap, id.vars="row")

interaction_pvals <- results_transformed_corrected_p[-(1:2),]
corrected_p_heatmap <- as.data.frame(interaction_pvals)
corrected_p_heatmap['row'] <- rownames(corrected_p_heatmap)
df.molten_p <- melt(corrected_p_heatmap, id.vars="row")
df.molten_p$stars <- cut(df.molten_p$value, breaks=c(-Inf, 0.001, 0.01, 0.05, Inf), label=c("***", "**", "*", ""))

# molten p heatmap for estimate replacement (non significant are black)
df.molten_est$stars = cut(df.molten_p$value, breaks=c(-Inf, 0.001, 0.01, 0.05, Inf), label=c("***", "**", "*", ""))
write.csv(df.molten_est,paste(output_path,"est_signif.csv"))


library(RColorBrewer)
# Custom function to create the required gradient
create_gradient_color <- function(value) {
  if (value <= -0.2) {
    "yellow"  # Solid blue for values <= -0.2
  } else if (value >= 0.2) {
    "blue"  # Solid green for values >= 0.2
  } else if (value < 0) {
    scales::col_numeric(palette = c("yellow", "white"), domain = c(-0.2, 0))(value)
  } else {
    scales::col_numeric(palette = c("white", "blue"), domain = c(0, 0.2))(value)
  }
}


# Define a sequence of values for the color scale
color_breaks <- seq(min(df.molten_est$value), max(df.molten_est$value), length.out = 100)
color_palette <- sapply(color_breaks, create_gradient_color)

df.molten_est$value[df.molten_p$value>0.05] <- NA

pdf(paste0(output_path_string,"_Residuals_HEATMAP.pdf"))
resi_plot <- ggplot(df.molten_est, aes(variable, row, fill= value)) +
        geom_tile() +
        scale_fill_gradientn(colours = color_palette) +
        ggtitle("estimate")
print(resi_plot)
dev.off()


pdf(paste0(output_path_string,"_Residuals_HEATMAP_number.pdf"))
resi_plot <- ggplot(df.molten_est, aes(variable, row, fill= value)) +
  geom_tile() +
  scale_fill_gradientn(colours = color_palette) +
  geom_text(aes(label = round(value, digits=2)), color = "black", size = 3)+
  ggtitle("estimate")
print(resi_plot)
dev.off()


ratio_heatmap <- as.data.frame(results_transformed_estimate[-1,])
ratio_heatmap_ratio = (as.numeric(ratio_heatmap[2,]) / as.numeric(ratio_heatmap[1,]))*100
ratio_heatmap <- rbind(ratio_heatmap, ratio_heatmap_ratio)
rownames(ratio_heatmap)[3] <- "ratio"
ratio_heatmap['row'] <- rownames(ratio_heatmap)

df.molten_ratio <- melt(ratio_heatmap, id.vars="row")
df.molten_ratio <- df.molten_ratio[df.molten_ratio$row == 'ratio',]
df.molten_ratio$star <- ifelse(df.molten_ratio$value > 10 | df.molten_ratio$value < -10, "*", "")
df.molten_ratio <- as.data.frame(df.molten_ratio)
write.csv(df.molten_ratio,paste(output_path,"ratio_signif.csv"))

df.molten_ratio$color <- ifelse(df.molten_ratio$star == "*", "With Star", "Without Star")


# Custom function to create the required gradient
create_gradient_color <- function(value) {
  if (value <= -300) {
    "blue"  # Solid blue for values <= -300
  } else if (value >= 300) {
    "red"  # Solid green for values >= 300
  } else if (value < 0) {
    scales::col_numeric(palette = c("blue", "white"), domain = c(-300, 0))(value)
  } else {
    scales::col_numeric(palette = c("white", "red"), domain = c(0, 300))(value)
  }
}
# Define a sequence of values for the color scale
color_breaks <- seq(min(df.molten_ratio$value), max(df.molten_ratio$value), length.out = 100)
color_palette <- sapply(color_breaks, create_gradient_color)


heatmap_plot <- ggplot(df.molten_ratio, aes(x = 1, y = variable, fill = value)) +
  geom_tile() +
  scale_fill_gradientn(colours = color_palette) +
  geom_text(aes(label = paste0(round(value, digits=2)," ",star)), color = "black", size = 3) +
  labs(x = "ratio", y = "Variable") +
  theme_minimal()


pdf(paste0(output_path_string,"_ratio_HEATMAP.pdf"))
print(heatmap_plot)
dev.off()

# Create the heatmap plot
heatmap_plot1 <- ggplot(df.molten_ratio, aes(x = 1, y = variable, fill = value)) +
  geom_tile() +
  scale_fill_gradientn(colours = color_palette) +
  geom_text(aes(label = paste0(round(value, digits=2))), color = "black", size = 3) +
  labs(x = "ratio", y = "Variable") +
  theme_minimal()


pdf(paste0(output_path_string,"_ratio_HEATMAP_nostars.pdf"))

print(heatmap_plot1)
dev.off()
```
